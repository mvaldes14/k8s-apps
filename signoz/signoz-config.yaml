apiVersion: v1
kind: ConfigMap
metadata:
  name: signoz-cm
  namespace: signoz
data:
  values.yaml: "global:\n  imageRegistry: &GLOBAL_IMAGE_REGISTRY null\n  storageClass: nfs-k8s-keep\n  clusterDomain: cluster.local\n  clusterName: \"\"\n  cloud: other\nnameOverride: \"\"\nfullnameOverride: \"\"\nclusterName: \"\"\nimagePullSecrets: []\nclickhouse:\n  enabled: true\n  zookeeper:\n    enabled: true\n    podAnnotations:\n      signoz.io/scrape: \"true\"\n      signoz.io/port: \"9141\"\n      signoz.io/path: \"/metrics\"\n    metrics:\n      enabled: true\n    logLevel: INFO\n    livenessProbe:\n      enabled: false\n    readinessProbe:\n      enabled: false\n    customLivenessProbe:\n      exec:\n        command: ['/bin/bash', '-c', 'curl -s -m 2 http://localhost:8080/commands/ruok | grep ruok']\n      initialDelaySeconds: 30\n      periodSeconds: 10\n      timeoutSeconds: 5\n      successThreshold: 1\n      failureThreshold: 6\n    customReadinessProbe:\n      exec:\n        command: ['/bin/bash', '-c', 'curl -s -m 2 http://localhost:8080/commands/ruok | grep error | grep null']\n      initialDelaySeconds: 5\n      periodSeconds: 10\n      timeoutSeconds: 5\n      successThreshold: 1\n      failureThreshold: 6\n    image:\n      registry: *GLOBAL_IMAGE_REGISTRY\n      repository: signoz/zookeeper\n      tag: 3.7.1\n    replicaCount: 1\n    namespaceOverride: \"\"\n    resources:\n      limits: {}\n      requests:\n        memory: 256Mi\n        cpu: 100m\n  namespace: \"\"\n  nameOverride: \"\"\n  fullnameOverride: \"\"\n  cluster: cluster\n  database: signoz_metrics\n  traceDatabase: signoz_traces\n  logDatabase: signoz_logs\n  meterDatabase: signoz_meter\n  user: admin\n  password: 27ff0399-0d3a-4bd8-919d-17c2181e6fb9\n  image:\n    registry: docker.io\n    repository: clickhouse/clickhouse-server\n    tag: 25.5.6\n    pullPolicy: IfNotPresent\n  imagePullSecrets: []\n  annotations: {}\n  serviceAccount:\n    create: true\n    annotations: {}\n    name:\n  service:\n    annotations: {}\n    type: ClusterIP\n    httpPort: 8123\n    tcpPort: 9000\n  secure: false\n  verify: false\n  externalZookeeper: {}\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  resources:\n    requests:\n      cpu: 100m\n      memory: 200Mi\n  securityContext:\n    enabled: true\n    runAsUser: 101\n    runAsGroup: 101\n    fsGroup: 101\n    fsGroupChangePolicy: OnRootMismatch\n  allowedNetworkIps:\n    - \"10.0.0.0/8\"\n    - \"100.64.0.0/10\"\n    - \"172.16.0.0/12\"\n    - \"192.0.0.0/24\"\n    - \"198.18.0.0/15\"\n    - \"192.168.0.0/16\"\n  persistence:\n    enabled: true\n    existingClaim: \"\"\n    storageClass: null\n    accessModes:\n      - ReadWriteOnce\n    size: 2Gi\n  profiles: {}\n  defaultProfiles:\n    default/allow_experimental_window_functions: \"1\"\n    default/allow_nondeterministic_mutations: \"1\"\n    default/secondary_indices_enable_bulk_filtering: \"0\"\n    admin/secondary_indices_enable_bulk_filtering: \"0\"\n    default/query_plan_max_limit_for_lazy_materialization: \"0\"\n    admin/query_plan_max_limit_for_lazy_materialization: \"0\"\n  initContainers:\n    enabled: true\n    udf:\n      enabled: true\n      image:\n        registry: docker.io\n        repository: alpine\n        tag: 3.18.2\n        pullPolicy: IfNotPresent\n      command:\n        - sh\n        - -c\n        - |\n          set -e\n          version=\"v0.0.1\"\n          node_os=$(uname -s | tr '[:upper:]' '[:lower:]')\n          node_arch=$(uname -m | sed s/aarch64/arm64/ | sed s/x86_64/amd64/)\n          echo \"Fetching histogram-binary for ${node_os}/${node_arch}\"\n          cd /tmp\n          wget -O histogram-quantile.tar.gz \"https://github.com/SigNoz/signoz/releases/download/histogram-quantile%2F${version}/histogram-quantile_${node_os}_${node_arch}.tar.gz\"\n          tar -xzf histogram-quantile.tar.gz\n          chmod +x histogram-quantile\n          mv histogram-quantile /var/lib/clickhouse/user_scripts/histogramQuantile\n          echo \"histogram-quantile installed successfully\"\n    init:\n      enabled: false\n      image:\n        registry: docker.io\n        repository: busybox\n        tag: 1.35\n        pullPolicy: IfNotPresent\n      command:\n        - /bin/sh\n        - -c\n        - |\n          set -e\n          until curl -s -o /dev/null http://signoz-clickhouse:8123/\n          do sleep 1\n          done\n  layout:\n    shardsCount: 1\n    replicasCount: 1\n  settings:\n    prometheus/endpoint: /metrics\n    prometheus/port: 9363\n  defaultSettings:\n    format_schema_path: /etc/clickhouse-server/config.d/\n    user_scripts_path: /var/lib/clickhouse/user_scripts/\n    user_defined_executable_functions_config: '/etc/clickhouse-server/functions/custom-functions.xml'\n  podAnnotations:\n    signoz.io/scrape: 'true'\n    signoz.io/port: '9363'\n    signoz.io/path: /metrics\n  podDistribution: []\n  coldStorage:\n    enabled: false\n  files:\n    config.d/formatting.xml: |\n      <clickhouse>\n        <logger>\n          <formatting replace=\"replace\">\n            <type>json</type>\n            <names>\n              <date_time>date_time</date_time>\n              <thread_name>thread_name</thread_name>\n              <thread_id>thread_id</thread_id>\n              <level>level</level>\n              <query_id>query_id</query_id>\n              <logger_name>logger_name</logger_name>\n              <message>message</message>\n              <source_file>source_file</source_file>\n              <source_line>source_line</source_line>\n            </names>\n          </formatting>\n        </logger>\n      </clickhouse>\n    config.d/crash.xml: |\n      <clickhouse>\n        <send_crash_reports replace=\"replace\">\n          <enabled>false</enabled>\n        </send_crash_reports>\n      </clickhouse>\n    config.d/load.xml: |\n      <clickhouse>\n        <async_load_databases replace=\"replace\">false</async_load_databases>\n      </clickhouse>\n    config.d/system_log.xml: |\n      <clickhouse>\n        <text_log>\n          <ttl>event_date + INTERVAL 3 DAY DELETE</ttl>\n        </text_log>\n        <latency_log>\n          <ttl>event_date + INTERVAL 3 DAY DELETE</ttl>\n        </latency_log>\n        <error_log>\n          <ttl>event_date + INTERVAL 7 DAY DELETE</ttl>\n        </error_log>\n        <query_metric_log>\n          <ttl>event_date + INTERVAL 3 DAY DELETE</ttl>\n        </query_metric_log>\n      </clickhouse>\n  installCustomStorageClass: false\n  clickhouseOperator:\n    name: operator\n    version: 0.21.2\n    image:\n      registry: docker.io\n      repository: altinity/clickhouse-operator\n      tag: 0.21.2\n      pullPolicy: IfNotPresent\n    imagePullSecrets: []\n    serviceAccount:\n      create: true\n      annotations: {}\n      name:\n    logger:\n      level: information\n      size: 1000M\n      count: 10\n      console: 1\n    queryLog:\n      ttl: 30\n      flushInterval: 7500\n    partLog:\n      ttl: 30\n      flushInterval: 7500\n    traceLog:\n      ttl: 7\n      flushInterval: 7500\n    asynchronousInsertLog:\n      ttl: 7\n      flushInterval: 7500\n    asynchronousMetricLog:\n      ttl: 30\n      flushInterval: 7500\n    backupLog:\n      ttl: 7\n      flushInterval: 7500\n    blobStorageLog:\n      ttl: 30\n      flushInterval: 7500\n    crashLog:\n      ttl: 30\n      flushInterval: 7500\n    metricLog:\n      ttl: 30\n      flushInterval: 7500\n    queryThreadLog:\n      ttl: 7\n      flushInterval: 7500\n    queryViewsLog:\n      ttl: 15\n      flushInterval: 7500\n    sessionLog:\n      ttl: 30\n      flushInterval: 7500\n    zookeeperLog:\n      ttl: 30\n      flushInterval: 7500\n    processorsProfileLog:\n      ttl: 7\n      flushInterval: 7500\n    podAnnotations:\n      signoz.io/port: '8888'\n      signoz.io/scrape: 'true'\n    nodeSelector: {}\n    metricsExporter:\n      name: metrics-exporter\n      service:\n        annotations: {}\n        type: ClusterIP\n        port: 8888\n      image:\n        registry: docker.io\n        repository: altinity/metrics-exporter\n        tag: 0.21.2\n        pullPolicy: IfNotPresent\nexternalClickhouse:\nsignoz:\n  name: \"signoz\"\n  replicaCount: 1\n  image:\n    registry: docker.io\n    repository: signoz/signoz\n    tag: v0.105.1\n    pullPolicy: IfNotPresent\n  imagePullSecrets: []\n  serviceAccount:\n    create: true\n    annotations: {}\n    name:\n  service:\n    annotations: {}\n    labels: {}\n    type: ClusterIP\n    port: 8080\n    internalPort: 8085\n    opampPort: 4320\n    nodePort: null\n    internalNodePort: null\n    opampInternalNodePort: null\n  annotations: []\n  additionalArgs: []\n  env:\n    signoz_telemetrystore_provider: clickhouse\n    dot_metrics_enabled: true\n    signoz_emailing_enabled: false\n    signoz_prometheus_active_query_tracker_enabled: false\n    signoz_alertmanager_provider: signoz\n    signoz_alertmanager_signoz_external__url: http://localhost:8080\n  initContainers:\n    init:\n      enabled: true\n      image:\n        registry: docker.io\n        repository: busybox\n        tag: 1.35\n        pullPolicy: IfNotPresent\n      command:\n        delay: 5\n        endpoint: /ping\n        waitMessage: \"waiting for clickhouseDB\"\n        doneMessage: \"clickhouse ready, starting query service now\"\n      resources: {}\n    migration:\n      enabled: false\n      image:\n        registry: docker.io\n        repository: busybox\n        tag: 1.35\n        pullPolicy: IfNotPresent\n      args: []\n      command: []\n      resources: {}\n  podSecurityContext: {}\n  podAnnotations: {}\n  securityContext: {}\n  additionalVolumeMounts: []\n  additionalVolumes: []\n  livenessProbe:\n    enabled: true\n    port: http\n    path: /api/v1/health\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  readinessProbe:\n    enabled: true\n    port: http\n    path: /api/v1/health?live=1\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  customLivenessProbe: {}\n  customReadinessProbe: {}\n  ingress:\n    enabled: false\n  resources:\n    requests:\n      cpu: 100m\n      memory: 100Mi\n  priorityClassName: \"\"\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  topologySpreadConstraints: []\n  persistence:\n    enabled: true\n    existingClaim: \n    storageClass: null\n    accessModes:\n      - ReadWriteOnce\n    size: 1Gi\nschemaMigrator:\n  enabled: true\n  name: \"schema-migrator\"\n  image:\n    registry: docker.io\n    repository: signoz/signoz-schema-migrator\n    tag: v0.129.7\n    pullPolicy: IfNotPresent\n  args:\n    - \"--up=\"\n  annotations: {}\n  upgradeHelmHooks: true\n  enableReplication: false\n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  topologySpreadConstraints: []\n  initContainers:\n    init:\n      enabled: true\n      image:\n        registry: docker.io\n        repository: busybox\n        tag: 1.35\n        pullPolicy: IfNotPresent\n      command:\n        delay: 5\n        endpoint: /ping\n        waitMessage: \"waiting for clickhouseDB\"\n        doneMessage: \"clickhouse ready, starting schema migrator now\"\n      resources: {}\n    chReady:\n      enabled: true\n      image:\n        registry: docker.io\n        repository: clickhouse/clickhouse-server\n        tag: 25.5.6\n        pullPolicy: IfNotPresent\n      command:\n        - \"sh\"\n        - \"-c\"\n        - |\n          echo \"Running clickhouse ready check\"\n          while true\n          do\n            version=\"$(CLICKHOUSE_VERSION)\"\n            shards=\"$(CLICKHOUSE_SHARDS)\"\n            replicas=\"$(CLICKHOUSE_REPLICAS)\"\n            current_version=\"$(clickhouse client --host ${CLICKHOUSE_HOST} --port ${CLICKHOUSE_PORT} --user \"${CLICKHOUSE_USER}\" --password \"${CLICKHOUSE_PASSWORD}\" -q \"SELECT version()\")\"\n            if [ -z \"$current_version\" ]; then\n              echo \"waiting for clickhouse to be ready\"\n              sleep 5\n              continue\n            fi\n            if [ -z \"$(echo \"$current_version\" | grep \"$version\")\" ]; then\n              echo \"expected version: $version, current version: $current_version\"\n              echo \"waiting for clickhouse with correct version\"\n              sleep 5\n              continue\n            fi\n            current_shards=\"$(clickhouse client --host ${CLICKHOUSE_HOST} --port ${CLICKHOUSE_PORT} --user \"${CLICKHOUSE_USER}\" --password \"${CLICKHOUSE_PASSWORD}\" -q \"SELECT count(DISTINCT(shard_num)) FROM system.clusters WHERE cluster = '${CLICKHOUSE_CLUSTER}'\")\"\n            if [ -z \"$current_shards\" ]; then\n              echo \"waiting for clickhouse to be ready\"\n              sleep 5\n              continue\n            fi\n            if [ \"$current_shards\" -ne \"$shards\" ]; then\n              echo \"expected shard count: $shards, current shard count: $current_shards\"\n              echo \"waiting for clickhouse with correct shard count\"\n              sleep 5\n              continue\n            fi\n            current_replicas=\"$(clickhouse client --host ${CLICKHOUSE_HOST} --port ${CLICKHOUSE_PORT} --user \"${CLICKHOUSE_USER}\" --password \"${CLICKHOUSE_PASSWORD}\" -q \"SELECT count(DISTINCT(replica_num)) FROM system.clusters WHERE cluster = '${CLICKHOUSE_CLUSTER}'\")\"\n            if [ -z \"$current_replicas\" ]; then\n              echo \"waiting for clickhouse to be ready\"\n              sleep 5\n              continue\n            fi\n            if [ \"$current_replicas\" -ne \"$replicas\" ]; then\n              echo \"expected replica count: $replicas, current replica count: $current_replicas\"\n              echo \"waiting for clickhouse with correct replica count\"\n              sleep 5\n              continue\n            fi\n            break\n          done\n          echo \"clickhouse ready, starting schema migrator now\"\n      resources: {}\n    wait:\n      enabled: true\n      image:\n        registry: docker.io\n        repository: groundnuty/k8s-wait-for\n        tag: v2.0\n        pullPolicy: IfNotPresent\n      env: []\n      resources: {}\n  serviceAccount:\n    create: true\n    annotations: {}\n    name:\n  role:\n    create: true\n    annotations: {}\n    name: \n    rules:\n      - apiGroups: [\"batch\"]\n        resources: [\"jobs\"]\n        verbs: [\"get\", \"list\", \"watch\"]\n    roleBinding:\n      annotations: {}\n      name: \notelCollector:\n  name: \"otel-collector\"\n  image:\n    registry: docker.io\n    repository: signoz/signoz-otel-collector\n    tag: v0.129.7\n    pullPolicy: IfNotPresent\n  imagePullSecrets: []\n  initContainers:\n    init:\n      enabled: false\n      image:\n        registry: docker.io\n        repository: busybox\n        tag: 1.35\n        pullPolicy: IfNotPresent\n      command:\n        delay: 5\n        endpoint: /ping\n        waitMessage: \"waiting for clickhouseDB\"\n        doneMessage: \"clickhouse ready, starting otel collector now\"\n      resources: {}\n  command:\n    name: /signoz-otel-collector\n    extraArgs:\n      - --feature-gates=-pkg.translator.prometheus.NormalizeName\n  configMap:\n    create: true\n  serviceAccount:\n    create: true\n    annotations: {}\n    name: \"\"\n  service:\n    annotations: {}\n    labels: {}\n    type: ClusterIP\n    loadBalancerSourceRanges: []\n  annotations:\n  podAnnotations:\n    signoz.io/scrape: 'true'\n    signoz.io/port: '8888'\n  podLabels: {}\n  additionalEnvs: {}\n  lowCardinalityExceptionGrouping: false\n  minReadySeconds: 5\n  progressDeadlineSeconds: 600\n  replicaCount: 1\n  clusterRole:\n    create: true\n    annotations: {}\n    name: \n    rules:\n      - apiGroups: [\"\"]\n        resources: [\"events\", \"pods\", \"pods/status\", \"namespaces\", \"namespaces/status\", \"nodes\", \"nodes/spec\", \"replicationcontrollers\", \"replicationcontrollers/status\", \"resourcequotas\", \"services\"]\n        verbs: [\"get\", \"list\", \"watch\"]\n      - apiGroups: [\"apps\"]\n        resources: [\"replicasets\", \"deployments\", \"daemonsets\", \"statefulsets\"]\n        verbs: [\"get\", \"list\", \"watch\"]\n      - apiGroups: [\"extensions\"]\n        resources: [\"replicasets\", \"daemonsets\", \"deployments\"]\n        verbs: [\"get\", \"list\", \"watch\"]\n      - apiGroups: [\"batch\"]\n        resources: [\"jobs\", \"cronjobs\"]\n        verbs: [\"get\", \"list\", \"watch\"]\n      - apiGroups: [\"autoscaling\"]\n        resources: [\"horizontalpodautoscalers\"]\n        verbs: [\"get\", \"list\", \"watch\"]\n    clusterRoleBinding:\n      annotations: {}\n      name: \n  ports:\n    otlp:\n      enabled: true\n      containerPort: 4317\n      servicePort: 4317\n      nodePort: \n      protocol: TCP\n    otlp-http:\n      enabled: true\n      containerPort: 4318\n      servicePort: 4318\n      nodePort: \n      protocol: TCP\n    metrics:\n      enabled: true\n      containerPort: 8888\n      servicePort: 8888\n      nodePort: \n      protocol: TCP\n    syslog: \n      enabled: true \n      containerPort: 54527\n      servicePort: 54527 \n      nodePort: \n      protocol: TCP\n  livenessProbe:\n    enabled: true\n    port: 13133\n    path: /\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  readinessProbe:\n    enabled: true\n    port: 13133\n    path: /\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 6\n    successThreshold: 1\n  customLivenessProbe: {}\n  customReadinessProbe: {}\n  extraVolumeMounts: []\n  extraVolumes: []\n  ingress:\n    enabled: false\n  resources:\n    requests:\n      cpu: 100m\n      memory: 200Mi\n  priorityClassName: \n  nodeSelector: {}\n  tolerations: []\n  affinity: {}\n  topologySpreadConstraints:\n    - maxSkew: 1\n      topologyKey: kubernetes.io/hostname\n      whenUnsatisfiable: ScheduleAnyway\n      labelSelector:\n        matchLabels:\n          app.kubernetes.io/component: otel-collector\n  podSecurityContext: {}\n  securityContext: {}\n  autoscaling:\n    enabled: false\n    minReplicas: 1\n    maxReplicas: 11\n    targetCPUUtilizationPercentage: 50\n    targetMemoryUtilizationPercentage: 50\n    behavior: {}\n    autoscalingTemplate: []\n    keda:\n      annotations:\n      enabled: false\n      pollingInterval: \"30\"\n      cooldownPeriod: \"300\"\n      minReplicaCount: \"1\"\n      maxReplicaCount: \"5\"\n      triggers: []\n  config:\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n            max_recv_msg_size_mib: 16\n          http:\n            endpoint: 0.0.0.0:4318\n      syslog:\n        tcp:\n          listen_address: 0.0.0.0:54527\n        protocol: rfc3164\n        location: UTC\n        operators:\n        - type: move\n          from: attributes.message\n          to: body\n      k8s_cluster:\n        collection_interval: 30s\n        allocatable_types_to_report: [\"cpu\", \"memory\", \"disk\"]\n    processors:\n      batch:\n        send_batch_size: 50000\n        timeout: 1s\n      k8sattributes:\n        auth_type: \"serviceAccount\"\n        passthrough: false\n        extract:\n          metadata:\n            - k8s.pod.name\n            - k8s.pod.uid\n            - k8s.deployment.name\n            - k8s.namespace.name\n            - k8s.node.name\n            - k8s.pod.start_time\n            - service.namespace\n            - service.name\n            - service.version\n            - service.instance.id\n          otel_annotations: true\n    extensions:\n      health_check:\n        endpoint: 0.0.0.0:13133\n    exporters:\n      clickhousetraces:\n        datasource: tcp://${env:CLICKHOUSE_USER}:${env:CLICKHOUSE_PASSWORD}@${env:CLICKHOUSE_HOST}:${env:CLICKHOUSE_PORT}/${env:CLICKHOUSE_TRACE_DATABASE}\n        low_cardinal_exception_grouping: ${env:LOW_CARDINAL_EXCEPTION_GROUPING}\n        use_new_schema: true\n      signozclickhousemetrics:\n        dsn: tcp://${env:CLICKHOUSE_USER}:${env:CLICKHOUSE_PASSWORD}@${env:CLICKHOUSE_HOST}:${env:CLICKHOUSE_PORT}/${env:CLICKHOUSE_DATABASE}\n        timeout: 45s\n      clickhouselogsexporter:\n        dsn: tcp://${env:CLICKHOUSE_USER}:${env:CLICKHOUSE_PASSWORD}@${env:CLICKHOUSE_HOST}:${env:CLICKHOUSE_PORT}/${env:CLICKHOUSE_LOG_DATABASE}\n        timeout: 10s\n        use_new_schema: true\n      otlphttp/victoriametrics:\n        compression: gzip\n        encoding: proto\n        metrics_endpoint: http://victoriametrics-svc.metrics:8428/opentelemetry/v1/metrics\n        logs_endpoint: http://victorialogs-svc.logs:9428/insert/opentelemetry/v1/logs\n        tls:\n          insecure: true\n    service:\n      telemetry:\n        logs:\n          encoding: json\n      extensions: [health_check]\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [batch, k8sattributes]\n          exporters: [clickhousetraces]\n        metrics:\n          receivers: [otlp, k8s_cluster ]\n          processors: [batch, k8sattributes]\n          exporters: [signozclickhousemetrics, otlphttp/victoriametrics]\n        logs:\n          receivers: [otlp, syslog]\n          processors: [batch, k8sattributes]\n          exporters: [clickhouselogsexporter, otlphttp/victoriametrics]\npostgresql:\n  enabled: false\nsignoz-otel-gateway:\n  enabled: false\nredpanda:\n  enabled: false\n"
